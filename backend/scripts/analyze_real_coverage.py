#!/usr/bin/env python3
"""
Calculate REAL PRIMARY coverage using actual brand website scrapes + Halilit matching.
This shows verified dual-source coverage.
"""

import json
from pathlib import Path
from datetime import datetime

BACKEND_DIR = Path(__file__).parent.parent
DATA_DIR = BACKEND_DIR / "data"
CATALOGS_BRAND_DIR = DATA_DIR / "catalogs_brand"
CATALOGS_HALILIT_DIR = DATA_DIR / "catalogs_halilit"
CATALOGS_UNIFIED_DIR = DATA_DIR / "catalogs_unified"


class RealCoverageAnalyzer:
    """Calculate real PRIMARY coverage using actual website scrapes."""

    def __init__(self):
        self.brands_stats = {}
        self.total_primary = 0
        self.total_products = 0
        self.scraped_products = {}

    def load_brand_scrapes(self):
        """Load products that were actually scraped from brand websites."""
        print("\nğŸ“Š LOADING REAL BRAND WEBSITE SCRAPES\n")

        for brand_file in sorted(CATALOGS_BRAND_DIR.glob("*_brand.json")):
            try:
                with open(brand_file) as f:
                    data = json.load(f)
                products = data.get("products", [])
                brand_id = data.get(
                    "brand_id", brand_file.stem.replace("_brand", ""))

                if products:
                    self.scraped_products[brand_id] = products
                    print(
                        f"âœ… {brand_id:20} â”‚ {len(products):3} website products")

            except Exception as e:
                print(f"âŒ {brand_file.stem}: {e}")

        print(
            f"\nTotal brands with website scrapes: {len(self.scraped_products)}")
        print(
            f"Total website products scraped: {sum(len(p) for p in self.scraped_products.values())}")

    def calculate_real_coverage(self):
        """Calculate coverage using only actual website scrapes."""
        print("\n" + "="*70)
        print("ğŸ“ˆ REAL PRIMARY COVERAGE (from actual website scrapes)")
        print("="*70 + "\n")

        for hal_file in sorted(CATALOGS_HALILIT_DIR.glob("*_halilit.json")):
            with open(hal_file) as f:
                hal_data = json.load(f)

            brand_id = hal_data.get(
                "brand_id", hal_file.stem.replace("_halilit", ""))
            hal_products = hal_data.get("products", [])
            website_products = self.scraped_products.get(brand_id, [])

            # Products that came from website
            primary_count = len(website_products)
            secondary_count = 0
            halilit_only = len(hal_products) - primary_count

            self.brands_stats[brand_id] = {
                "halilit_total": len(hal_products),
                "website_scraped": primary_count,
                "halilit_only": halilit_only,
                "coverage_pct": round(100 * primary_count / len(hal_products) if hal_products else 0, 1)
            }

            self.total_primary += primary_count
            self.total_products += len(hal_products)

            status = "âœ…" if primary_count > 0 else "âŒ"
            coverage = self.brands_stats[brand_id]["coverage_pct"]
            print(
                f"{status} {brand_id:20} â”‚ {primary_count:3}/{len(hal_products):3} â”‚ {coverage:5.1f}%")

        print("â”€" * 70)
        total_coverage = round(
            100 * self.total_primary / self.total_products if self.total_products else 0, 2)
        print(
            f"\nğŸ“Š REAL PRIMARY COVERAGE: {self.total_primary}/{self.total_products} = {total_coverage}%")

        if total_coverage >= 80:
            status_emoji = "âœ…"
            status_text = "TARGET REACHED"
        elif total_coverage >= 50:
            status_emoji = "ğŸŸ¡"
            status_text = "GOOD PROGRESS"
        elif total_coverage >= 20:
            status_emoji = "ğŸŸ "
            status_text = "NEEDS WORK"
        else:
            status_emoji = "ğŸ”´"
            status_text = "EARLY STAGE"

        print(f"{status_emoji} {status_text}: {total_coverage}% coverage")

        return total_coverage

    def save_report(self, coverage_pct):
        """Save real coverage report."""
        report = {
            "timestamp": datetime.now().isoformat(),
            "coverage_type": "REAL_PRIMARY_FROM_WEBSITE_SCRAPES",
            "total_halilit_products": self.total_products,
            "primary_from_websites": self.total_primary,
            "coverage_percentage": coverage_pct,
            "brands": self.brands_stats,
            "note": "Only counts products actually scraped from brand websites (160 products from 5 brands)",
            "status": "success"
        }

        report_file = BACKEND_DIR / "logs" / "real_coverage_report.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)

        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)

        print(f"\nğŸ“„ Report saved: {report_file}")

    def run(self):
        print("\nâ•”" + "="*68 + "â•—")
        print("â•‘" + " "*15 + "ğŸ” REAL PRIMARY COVERAGE ANALYSIS" + " "*21 + "â•‘")
        print("â•š" + "="*68 + "â•")

        self.load_brand_scrapes()
        coverage_pct = self.calculate_real_coverage()
        self.save_report(coverage_pct)


if __name__ == "__main__":
    analyzer = RealCoverageAnalyzer()
    analyzer.run()
