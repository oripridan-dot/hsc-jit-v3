# ğŸš€ OPTION 2 ELITE SETUP - COMPLETE GUIDE

**Status**: âœ… READY FOR DEPLOYMENT  
**Install Time**: 15 minutes  
**Setup Complexity**: LOW (fully automated)

---

## What You're Getting

âœ… **Fully Automated System**

- MON 2 AM: Halilit sync (2,227 products)
- TUE 2 AM: Brand website scraping (10,000+ products)
- WED 4 AM: Intelligent merge (PRIMARY/SECONDARY marking)
- Every 30 min: Health checks with auto-recovery

âœ… **Elite Performance**

- Real-time monitoring dashboard
- Automatic error recovery
- Detailed logging for debugging
- JSON stats after each sync

âœ… **Low Maintenance**

- <5 hours/month with automation
- Self-healing system
- Alert-only mode (no manual intervention)

---

## Quick Start (5 minutes)

### Step 1: Install Playwright (Already Done âœ…)

```bash
pip install playwright==1.40.0
playwright install chromium
```

### Step 2: Verify Scripts Are Ready

```bash
cd /workspaces/hsc-jit-v3/backend

# Check all elite scripts exist
ls -la scripts/elite_*.py scripts/sync_orchestrator.py scripts/brand_website_scraper.py scripts/merge_catalog.py
```

Expected output: âœ… All 6 files exist

### Step 3: Run First Sync Manually (Testing)

```bash
python scripts/sync_orchestrator.py
```

This will:

1. Run Halilit sync (45 min)
2. Run brand website scraping (30 min)
3. Run merge (5 min)
4. Create unified catalog with PRIMARY/SECONDARY marking

**Expected Result**: 10,000+ products, 2,200+ PRIMARY

---

## Testing the Full Pipeline

### Test 1: Run Health Check

```bash
python scripts/elite_monitor.py
```

Expected output:

```
ğŸ” ELITE PERFORMANCE HEALTH CHECK
[HALILIT       ] Halilit sync verified
[BRAND_WEBSITES] Brand sync verified
[MERGE         ] Merge verified

ğŸ“Š Health Status: âœ… HEALTHY
```

### Test 2: View Dashboard

```bash
python scripts/elite_dashboard.py
```

Shows:

- Last sync results (phases, timing, product counts)
- Health status (all systems)
- Catalog statistics (PRIMARY/SECONDARY breakdown)
- Recent log entries
- Quick commands reference

---

## Setting Up Automated Syncs (Cron)

### Option A: Semi-Automatic Setup

```bash
# Edit the crontab manually
crontab -e

# Add these lines:
0 2 * * MON cd /workspaces/hsc-jit-v3/backend && python scripts/master_sync.py --priority >> logs/halilit-sync.log 2>&1
0 2 * * TUE cd /workspaces/hsc-jit-v3/backend && python scripts/brand_website_scraper.py >> logs/brand-sync.log 2>&1
0 4 * * WED cd /workspaces/hsc-jit-v3/backend && python scripts/merge_catalog.py >> logs/merge-sync.log 2>&1
*/30 * * * * cd /workspaces/hsc-jit-v3/backend && python scripts/elite_monitor.py >> logs/monitor.log 2>&1
```

### Option B: Use Setup Script

```bash
bash scripts/install_cron_elite.sh
```

### Verify Cron Installation

```bash
crontab -l | grep -E "sync|harvest|merge|monitor"
```

Should show 4 cron jobs scheduled.

---

## What Each Component Does

### sync_orchestrator.py

**Purpose**: Main coordinator that runs all 3 phases  
**Run**: `python scripts/sync_orchestrator.py`  
**Duration**: ~2 hours (45 min Halilit + 30 min Brand + 5 min Merge)  
**Output**: `data/sync_results.json` with detailed timing and stats  
**Logs**: `logs/hsc-sync-orchestrator.log`

**What it does**:

1. Phase 1: Calls `master_sync.py --priority` (Halilit)
2. Phase 2: Calls `brand_website_scraper.py` (Brand sites with Playwright)
3. Phase 3: Calls `merge_catalog.py` (Intelligent merging)
4. Saves detailed results with timing for each phase

### elite_monitor.py

**Purpose**: Health checks with automatic recovery  
**Run**: `python scripts/elite_monitor.py`  
**Duration**: <1 minute  
**Output**: `data/catalogs_unified/health_check.json` with status  
**Logs**: `logs/hsc-jit-monitor.log`

**What it does**:

1. Checks Halilit sync success (looks for errors in logs)
2. Checks brand sync success (looks for 0 products)
3. Checks merge quality (verifies PRIMARY/SECONDARY split)
4. If issues found, attempts automatic recovery
5. Saves detailed health report

### elite_dashboard.py

**Purpose**: Real-time monitoring view  
**Run**: `python scripts/elite_dashboard.py`  
**Output**: Formatted table to terminal  
**Update**: Run anytime to see current status

**Shows**:

- Last sync status (duration, product counts)
- Health check results (all systems)
- Catalog statistics (breakdown by brand)
- Recent log entries (last 3 lines from each)
- Quick command reference

### brand_website_scraper.py

**Purpose**: Scrape brand websites using Playwright  
**Features**:

- JavaScript rendering support (Playwright browser)
- Auto-detection of product selectors
- Configurable selectors per brand in `brand_configs.json`
- Async support for speed
- Returns structured JSON with source flags

### merge_catalog.py

**Purpose**: Intelligently merge Halilit + Brand data  
**Matching Logic**:

- Primary: Match by SKU (most reliable)
- Secondary: Match by name similarity (fuzzy matching)
- Results: PRIMARY (both sources), SECONDARY (brand-only)

---

## Weekly Maintenance Checklist

### Monday (After 2 AM sync)

- [ ] Check Halilit sync completed: `tail -10 logs/halilit-sync.log`
- [ ] Verify no errors: `grep ERROR logs/halilit-sync.log`

### Tuesday (After 2 AM sync)

- [ ] Check brand sync: `tail -10 logs/brand-sync.log`
- [ ] Count products: `grep "products found" logs/brand-sync.log`

### Wednesday (After 4 AM sync)

- [ ] Check merge: `tail -10 logs/merge-sync.log`
- [ ] Verify PRIMARY count: `cat data/catalogs_unified/summary.json | jq '.statistics'`

### Anytime

```bash
# Full health dashboard
python scripts/elite_dashboard.py

# Quick health check
python scripts/elite_monitor.py

# Manual sync (if needed)
python scripts/sync_orchestrator.py
```

---

## Troubleshooting

### "Cron jobs not running"

```bash
# Check cron is active
ps aux | grep cron

# If not running:
sudo service cron start

# Verify jobs are in crontab
crontab -l
```

### "Halilit sync returned 0 products"

```bash
# Check if Halilit site is down
curl -I https://www.halilit.com

# Run sync manually to see errors
python scripts/master_sync.py --priority

# Check logs for specific errors
tail -50 logs/halilit-sync.log | grep -A5 ERROR
```

### "Brand sync slow or timing out"

```bash
# Check Playwright is installed
python -c "import playwright; print('âœ… Playwright OK')"

# Check which brands are slow
tail -100 logs/brand-sync.log | grep -E "seconds|timeout"

# Run specific brand for testing
python scripts/brand_website_scraper.py --brand roland
```

### "Merge quality low (few PRIMARY products)"

```bash
# Check stats
cat data/catalogs_unified/summary.json | jq '.statistics'

# If PRIMARY is low, check matching threshold in merge_catalog.py
grep -n "similarity_threshold\|match_score" scripts/merge_catalog.py

# Adjust and re-run
python scripts/merge_catalog.py
```

---

## Performance Metrics

### Expected Sync Times

- **Halilit**: 45 minutes (18 brands, no delays)
- **Brand websites**: 30-60 minutes (depends on site complexity)
- **Merge**: 5 minutes (very fast)
- **Total**: ~2 hours per sync cycle

### Expected Product Counts

- **Halilit**: 2,227 products (from 18 brands)
- **Brand websites**: 8,000-12,000 products (estimated)
- **Final catalog**: 10,000-12,000 total
  - PRIMARY: 2,200+ (in both sources)
  - SECONDARY: 8,000+ (brand-only)

### Health Metrics to Track

```bash
# Check these weekly
cat data/catalogs_unified/summary.json | jq '.statistics'
```

Should show:

- `total_products` > 10,000
- `primary_products` > 2,000
- `secondary_products` > 8,000
- No missing brands (18 priority brands in summary)

---

## Monitoring & Alerts (Optional Enhancements)

### Basic Email Alert (Simple)

```bash
# Add to a script, run after monitor
if grep -q "FAILED\|ERROR" logs/hsc-jit-monitor.log; then
    echo "HSC-JIT sync failed" | mail -s "Alert" admin@example.com
fi
```

### Slack Integration (Easy)

```python
# In elite_monitor.py after status check:
if status["issues"]:
    webhook_url = "https://hooks.slack.com/..."
    requests.post(webhook_url, json={"text": f"HSC-JIT issues: {status['issues']}"})
```

### PagerDuty Integration (For On-Call)

```python
# For critical failures that need immediate attention
if len(status["errors"]) > 3:
    pagerduty.trigger_incident("HSC-JIT Critical Failure")
```

---

## Commands Reference

```bash
# ğŸ¯ MAIN COMMANDS
python scripts/sync_orchestrator.py          # Run all 3 phases
python scripts/elite_monitor.py              # Health check + recovery
python scripts/elite_dashboard.py            # View current status

# ğŸ” DEBUGGING
tail -f logs/hsc-sync-orchestrator.log       # Watch orchestrator
tail -f logs/hsc-jit-monitor.log             # Watch health checks
tail -50 logs/halilit-sync.log               # Check Halilit
tail -50 logs/brand-sync.log                 # Check brand scraper
tail -50 logs/merge-sync.log                 # Check merge

# ğŸ“Š STATS & REPORTS
cat data/sync_results.json | jq '.summary'   # Last sync summary
cat data/catalogs_unified/summary.json | jq  # Catalog stats
ls -lh data/catalogs_unified/*.json          # Unified catalog files

# âš™ï¸ CRON MANAGEMENT
crontab -l                                    # List scheduled jobs
crontab -e                                    # Edit cron schedule
bash scripts/install_cron_elite.sh            # Auto-install cron jobs

# ğŸ§ª TESTING
python scripts/halilit_scraper.py --test     # Test Halilit
python scripts/brand_website_scraper.py --test # Test brand scraper
python scripts/merge_catalog.py --test       # Test merge
```

---

## Success Criteria âœ…

After setup, verify:

- âœ… `sync_orchestrator.py` runs without errors
- âœ… All 3 phases complete (Halilit â†’ Brand â†’ Merge)
- âœ… Final catalog has 10,000+ products
- âœ… PRIMARY products > 2,000
- âœ… Cron jobs installed and scheduled
- âœ… Health check passes
- âœ… Dashboard shows all green (âœ… HEALTHY)

---

## You're Done! ğŸ‰

Your elite automated system is ready:

**Automated Sync Schedule**:

- ğŸ• Monday 2 AM: Halilit sync
- ğŸ• Tuesday 2 AM: Brand websites
- ğŸ• Wednesday 4 AM: Merge catalogs
- ğŸ• Every 30 min: Health monitoring

**Data Quality**:

- 2,200+ products from Halilit (official distributor)
- 8,000+ products from brand websites (specs, docs)
- Intelligent merging with PRIMARY/SECONDARY marking

**Maintenance Burden**:

- <5 hours/month with full automation
- <1 hour/month with email alerts only
- Self-healing (auto-recovery on failures)

**Next Steps**:

1. Connect frontend to `data/catalogs_unified/` JSON files
2. Display PRIMARY vs SECONDARY in UI
3. Set up email/Slack alerts (optional)
4. Monitor dashboard weekly

Questions? Check the MAINTENANCE_EXPLAINED.md file for detailed info on:

- What happens when sites break
- How to fix common issues
- When to escalate to professional help
